---
layout: post
title: Feature Selective Anchor Free
date: 2019-07-16 11:53
category: Post
author: Ezobear
use_math : True
tags: [Object Detection, SSD, Onshot Detect]
summary: 기존 휴리스틱하게 사용했더 default box를 network 를 통해 학습시켜보고자한 시도그러나 기존 방식을 대체할수는 없음. 다만 small object를 더 잘 잡고, 기존 default box와 다른 객체를 찾음. 따라서 anchor-free branch 와 같이 사용되면 더 효과가 좋을것임
---

Title
=============
Feature Selective Anchor-Free Module for Single-Shot Object Detection
CVPR 2019

Introduction
=============
기존의 SSD와 같은 single-shot detector들의 경우 Anchor 기반으로 Detecting을 진행합니다. 하지만 본 논문에서는 이러한 Anchor 기반의 Detecting 방식에는 2가지의 한계가 있다고 지적하였습니다.<br>

1.heuristic-guide를 통한 feature selection<br>
2.overlap-based anchor sampling<br>

본 논문에서는 이러한 2가지 문제를 FSAF(Feature-Selective-Anchor-Free)를 통해 해결하고자 하였습니다.<br>

결론부터 얘기하자면 이러한 Anchor - Free Module 은 기존의 Single Shot Detector들의 Anchor 방식을 대체할수는 없습니다. 그러나 기존의 Anchor 방식으로 Detecting 되는 Object들과는 다른 Ojbect들을 찾아내었고 이 두가지를 같이 사용하면 좀 더 높은 성능을 갖는 Detector를 만들 수 있다고 주장했습니다.<br>

특히 Small Object에 대해 강한 성능을 보이며 가볍고 플러그 인 하기가 쉽다는 장점을 갖습니다. 위에는 Qualitative Result 결과입니다. 이를 Quantitative하게 보면 아래 표와 같습니다.<br>

Retina 800을 기준으로 mAP는 3.7% 증가하였으며, 특히 Small Object에 대해 6% 증가한 것을 볼 수 있습니다. 다만 이것이 Resolution이 800으로 충분히 클때의 성능이므로 작은 Resolution에서 어떻게 동작할지는 실험이 필요할 것 입니다.<br>

이때 속도측면에서도 비교해보면 Anchor Based(AB) 방식과 FSAF방식을 둘 다 사용할 경우 성능이 가장 많이 오른것으로 확인할 수 있으며, 속도 또한 크게 차이나지 않습니다.<br>

자세한 방법에 대한 설명은 아래와 같습니다.<br>

Feature Selective Anchor-Free
=============

위의 그림의 경우 FSAF의 전체 Network Architecture인데, FPN에서 빠져나온 Fautre map이 각 Layer 별로 Predict됩니다. 이때 기존의 Anchor - based branch 로 빠지게되는데 여기까지가 기존의 FPN + SSD의 기본 구조로 FSAF는 이 Baseline에 Plugin 되게 됩니다.<br>

이때 Fature Map이 Anchor based branch로 빠지는 시점에 동시에 Anchor - Free branch로 빠지게되는데 이 과정이 본 논문에서 제안하는 FSAF의 기본구조입니다. 이후 Anchor Free Branch 에서 빠져나온 loss 값들을 이용하여 Online Feture Selection을 진행하게되는데 자세한 내용은 이후 살펴보도록 하겠습니다.<br>

## 1. Feature Selective Anchor-Free Module
저자들은 FSAF Module의 경우 가볍고 빠르고, 플러그인 시키기 쉽다고 저자들은 주장했습니다. 이 말이 그럴수밖에 없는게 FSAF는 3 by 3 Conv2D 가 끝입니다. 아차 이게 뭔가싶긴한데 일단 잘 동작하니깐 살펴봅시다. 모듈자체에 대해서는 크게 설명할게 없기 때문에 본 저자들이 어떻게 학습시켰는지 크게 2가지 관점에서 살펴봅시다. 첫번째는 자세히 살펴보기 앞서 Notation에 대해 소개합니다. 두번째는 Ground-truth와 Loss Function에 대해 살펴보도록 하겠습니다.<br>

* ### Notation

Bounding Box
>$$b=[x,y,w,h]$$ (1)
일반적인 Bounding Box의 Notation입니다. x,y는 box의 centor 좌표이고, w,h는 width 와 height입니다.<br>
##

Multi-layer Bounding Box<br>
> $$b_p^l= [x_p^l, y_p^l, w_p^l, h_p^l]$$(2)
Multi-layer Bounding Box는 Bounding Box의 확장 버전으로, FPN에서 Bounding Box가 어느 Layer에 포함되어있는지 표시합니다. 피라미드($p$)의 ($l$)번째 layer 에 속해있다는 뜻입니다. 이러한 Multi-layer Bounding Box는 2개의 Type이 존재합니다. 첫번째는 Effective Bounding Box이고, 두번째는 Ignore Bounding Box입니다.<br>
##

Notation<br>
> $$ x_e^l = x_i^l = x_p^l$$
> $$ y_e^l = y_i^l = y_p^l$$
> $$ w_e^l = \epsilon_e w_p^l$$
> $$ w_i^l = \epsilon_i w_p^l$$
> $$ h_e^l = \epsilon_e h_p^l$$
> $$ h_i^l = \epsilon_i h_p^l$$

이때 $\epsilon$은 Bounding Box Scale에 영향을 미치는 가중치로써, $\epsilon_e$와 $\epsilon_i$가 있습니다. 이는 각각 Effective Region에 대한 가중치와 Ignoring Region에 대한 가중치입니다.<br>

* ### Method
그림의 경우 FSAF Moudle의 그림입니다. 이때 FSAF Module의 경우 Class Module과 Box Regression Module 2개로 구성됩니다.<br>

 * Class Module 
 Class Module의 경우 크게 3가지의 영역을 갖습니다.<br>

 1. Effective Region

> $$b_e^l= [x_e^l, y_e^l, w_e^l, h_e^l]$$(3)

그림에서 흰색 영역입니다. Instance가 존재하는 영역으로 positive value 로 채워져있으며, 직접적인 학습에 영향을 미치는 영역입니다. 만약에 한 레벨에서 Effective Region이 겹치게 될 경우 작은 Effective Region(Small Object)가 우선순위를 갖게 됩니다.<br>

 2. Ignoring Region

> $$b_i^l= [x_i^l, y_i^l, w_i^l, h_i^l]$$(4)

그림에서 회색 영역입니다. Igroing Bounding Box 에서 Effective Region을 제외한 영역($b_i^l-b_e^l$)으로 이 영역은 gradient를 back propagation 시키지 않습니다. <br>

> Influence of Ignoring Region  on Adjacent<br>

이때 중요한것은 Ignoring Region은 다른 Adjacent Layer($b_i^l-1,b_i^l+1$) 들에 영향을 미친다는 것 입니다. 이때 Adjacent Layer에서 이미 instance가 존재하더라도 l번째 Lyaer에서 Ingoring Region이 발생하면  Adjacent Layer의 영역 또한 Ingnoring Region이 됩니다. <br>

 3. Rest Region<br>
 Rest Region의 경우 Instance가 존재하지 않는 Region으로 zero-fill 됩니다.<br>


 * Box Regression Module
>$$Prior\ Box = (i-S\hat{o}_{t_{i,j}},j-S\hat{o}_{l_{i,j}},i+S\hat{o}_{b_{i,j}},j+S\hat{o}_{r_{i,j}})$$(5)
>$$offset\ maps = d_{i,j}^l/S $$(6)
>$$ d_{i,j}^l = [ d_{t_{i,j}}^l,d_{l_{i,j}}^l,d_{b_{i,j}}^l,d_{r_{i,j}}^l]$$(7)

Box Regression Module이 학습시키는 것은 $(i,j)$ 번째 중심좌표로부터의 distance(top, left,bottom,right)입니다. 이때 offset\ maps은 수식 (5)와 같이 계산됩니다. 이때 S는 normalization constant입니다. 위의 그림에서 보다시피 Box Regression Module 역시 Ignore Region과 Effective Region이 있으며, Ignore Region은 Back Propagation하지 않습니다.<br>
이때 Prior Box는 $(i,j)$번째 좌 $S$와 Distance간의 곱으로 계산됩니다.<br>

* ### Loss Function
본 논문에서는 Retinanet을 기반으로 하였기 때문에 Classification Loss Function은 Focal Loss를 사용하였고, Box Regression Loss는 IOU Loss Function을 사용하였습니다.<br>

* ### Hyper-Prameter
> $$ \epsilon_e = 0.2$$<br> $$ \epsilon_i = 0.5$$<br> $$ S = 4.0$$<br>
##
위에서 사용된 Hyper-Prameter들의 값으로 논문에서는 실험적으로 획득하였다고 합니다.<br>

## 3. Online Feture Selection

아키텍처에서 FPN에서 각 Layer 별로 Feature Map이 나오게됩니다. 이때 각 Layer에서 Anchor-Free Branch로 들어간 Feature Map은 focal loss와 IoU loss를 return 하게 됩니다. 이때 feature map에서 나온 각 Instance에 대한 loss를 Sumation하여 minimize하는 l을 찾습니다. 이때 찾은 가장 작은 l이 Instance로써 학습됩니다.<br>

## 4. Demo

위의 그림은 FSAF의 결과입니다. Label에서 가장 왼쪽의 숫자는 이 instance를 찾아낸 Layer의 번호입니다. 그리고 red box는 anchor free module 만 찾아낸 instance이고, green box의 경우 anchor based 와 anchor free가 같이 찾아낸 instance입니다. <br>

