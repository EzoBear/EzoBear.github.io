---
layout: post
title: Localization & Bounding Box Regression for Object Detection Focusing on IOU
date: 2020-01-02 12:42
category: IOU
author: Ezobear
tags: [IoU, Intersection Over Union, GIoU, DIoU, CIoU]
excerpt: 여태까지의 객체 검출에서의 연구는 검출기의 아키텍처 변경을 통한 Feature Level의 성능향상이나 Focal Loss등을 통한 Classification에서의 성능 향상을 주로 다루었습니다. 이번 포스팅에서 IOU Loss의 발전에 대해 다루려고 합니다. 이러한 연구 방향은 기존의 발전과는 다르게 Boundung Box Regression에서의 성능 향상을 보였다는 점에서 Novelty가 있습니다. 이는 객체검출기에서의 새로운 발전 방향을 제시합니다.
use_math: true
---

Introduction
=============
<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure1.png?raw=true" alt="Figure1">

Localization은 객체검출기에서 가장 중요한 능력 중 하나입니다. 객체검출기는 Localization을 위해 Feature Map을 기반으로 Object가 존재하는 위치에 Bounding Box를 그리게 됩니다. 이러한 동작은 Bounding Box Regression이라 합니다. 이러한 Bounding Box Regression의 성능을 측정하기 위해서 실제 객체와 예측된 객체간의 IOU를 계산함으로써 Localization 성능을 측정하게 됩니다. 

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure2.png?raw=true" alt="Figure2">

객체검출 문제에서 Localization의 발전은 크게 2가지 방향으로 발전됩니다. 첫번째는 다양한 형태의 Bounding Box Regression을 수행함으로써 보다 정확한 객체의 Localization을 Estimation하는 방향으로 Segment Detection, Polygonal Detection, Free-Shape Detection 혹은 Instance Segmentation 등 여러 이름으로 불리고 있습니다[1][2][3][4][5][6][7]. 이 경우는 다양한 Shape의 Detection을 수행하기 때문에 다양한 모양의 IOU를 구하는 방법에 대해 다루는 경우도 있습니다. 

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure3.png?raw=true" alt="Figure3">

두번째 방향은 최근 연구가 되고 있는 방향으로, 기존 IOU Measure 자체에 주목하여 Jarccard Index의 Measure 및 Loss로써의 한계 지적하고 이를 개선하는 방향입니다[8][9]. 두번째 방향이 중요한 이유는 다음과 같습니다. 여태까지의 객체 검출에서의 연구는 검출기의 아키텍처 변경을 통한 Feature Level의 성능향상이나 Focal Loss를 통한 Classification에서의 성능 향상을 주로 다루었다면, 이번 포스팅에서 다룰 두번째 방향은 Boundung Box Regression에서의 성능 향상을 보였다는 점입니다. 이는 여태까지 없던 시도였고, 충분히 객체검출기에서의 새로운 기회로 보이기 때문에 중요한 연구분야로 자리잡을것으로 보입니다. 따라서 본 포스팅에서는 두번째 소개해드린 IOU의 발전에 대해 중점적으로 다루고자 합니다.

IOU(Intersection Over Union)
=============

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure4.png?raw=true" alt="Figure4">

IOU는 객체검출 문제에서 전통적으로 Localization을 평가하기 위한 Measure로 사용되어왔습니다. 이러한 IOU는 두개의 객체가 겹치는 부분을 측정함으로써 Localization능력을 평가해왔습니다. 이러한 IOU는 기존의 Jaccard index 혹은 Jaccard similarity coefficient라고 불리는 Measure로 측정되어왔습니다. 

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure5.png?raw=true" alt="Figure5">

Jaccard Index는 위와 같이 표현되며, 이는 A와 B의 합집합에서의 A와 B의 교집합으로 표현됩니다. 이러한 Jaccard Index의 성질은 결과가 0과 1사이에서 정의된다는 것입니다. 이러한 Property는 박스의 Width, Height 정보를 Encoding한 정보이며, 이러한 정보는 객체검출 문제에서 두개의 객체사이의 겹치는 비율을 Nomalization된 결과 혹은 Probability로써도 볼 수 있도록 합니다. 또한 이를 통하여 IOU가 Scale Invariant 하다는 장점 또한 갖게됩니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure6.png?raw=true" alt="Figure6">

또한 이러한 성질을 통해 유사성이 아닌 거리로써 표현될 수도 있습니다. 위 수식은 Jaccard Similarity 1에서 빼줌으로써 기존과 반대의 성질을 부여하게됩니다. 기존에는 교집합이 크면 1, 작으면 0에 가까운 수로 표현되었는데, 1에서 빼줌으로써 많이 겹치면 0, 겹치지 않는다면 1로 표현되게 됩니다. 이는 객체검출 문제에서 겹치는 객체끼리의 거리는 가깝고, 겹치지 않는 객체끼리의 거리는 멀다는 특징을 잘 살린 Distance Mesaure로써 사용할 수 있게 해줄뿐만 아니라 Loss로써도 직접적으로 사용할 수 있도록 해줍니다.

GIOU(Generalized IOU)
=============

GIOU는 IOU의 확장버전입니다. 핵심부터 말하자면 GIOU는 기존의 Jarcard Index에 Regularize Term을 추가한 형태로 크게 2가지 관점에서의 개선을 보입니다. 첫번째는 Jarcard Index가 2개의 객체가 Overlapping되어있지 않다면, Gradient 값이 0으로 학습에 관여할 수 없는 Gradient Vanishing 문제가 발생한다는 점과 얼마나 두 객체가 멀리 떨어져있는지는 반영하지 못한다는 점을 개선합니다. 두번째는 GIOU가 Jarcard Index의 IOU에 비해 좀 더 타이트하고 실제와 유사한 Stronger Shape에 대한 정보를 반영함을 보이고, 이를 통해 성능적인 개선을 보입니다. 자세한 내용은 아래에서 다루겠습니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure7.png?raw=true" alt="Figure7">

위 알고리듬 표는 GIOU의 간략화된 버전입니다. Input에서 A,B는 각 객체의 Bounding Box이며, 이들은 Scale 공간 S에 속하고, S는 N차원의 R Space에 속합니다. 이때 C는 Smallest Enclosing Convex Object로, 2개의 박스 A와 B를 포함하는 가장 작은 박스입니다. 이때 Regularize term은 C에서 A와 B의 영역을 뺀 나머지 값이 되는데, 이를 IOU에서 마이너스함으로써 GIOU를 구할 수 있습니다. 이를 시각화해서 표현하면 아래와 같습니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure8.png?raw=true" alt="Figure8">

위의 그림이 C를 설명하는 그림으로, 빨간색이 Predicted Box이고, 초록색이 Ground Truth라 할때 이 두개를 감싸고 있는 검은 Box가 Smallest Enclosing Convex Object인 C를 의미합니다. 본 연구에서는 C를 통하여 첫번째 문제인 Jarcard Index가 2개의 객체가 Overlapping되어있지 않다면, 값이 0으로 학습에 관여할 수 없다는 점과 얼마나 두 객체가 멀리 떨어져있는지는 반영하지 못한다는 점을 개선하였습니다. 자세한 내용은 몇가지 시나리오와 함께 아래서 확인해보겠습니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure9.png?raw=true" alt="Figure9">

위 그림에서는 3개의 시나리오를 다루고있는데, 좌측부터 A와B가 완전히 겹칠때, A와 B가 겹치지 않았지만 딱 붙어있을때, A와 B가 겹치지 않고 거리가 멀때입니다. 첫번째 시나리오에서 보면, A와 B는 완전히 겹쳐있습니다. 이는 $IOU$가 $1$이고, $C$는 $0$인 상황입니다. 이는 $GIOU$의 $Regularzie term$의 분모가 $0$이되게 됩니다.즉, $GIOU = IOU - 0$임으로 $IOU$가 되게됩니다. 이는 완전히 겹치는 상황에서는 $IOU$와 동일하게 동작함을 보입니다. 이 부분에 대해서 좀 더 자세하게 설명드리면, $GIOU = IOU - (A^c - U) / A^c$입니다. 이때 $A^c$는 C의 Area를 뜻하며, U는 $A^p + A^g -I$ 를 뜻합니다. 이때 $I$는 $B^p$와 $B^g$의 Interecntion입니다. 이때 $p$와 $g$는 $predict$와 $gt$를 의미합니다. 여기서 $A$와 $B$가 완전히 겹치면, $A^p = A^g = I = A^c$가 되게됩니다. 즉, 이를 $GIOU$에 대입하여 생각하면 분모가 다 상쇄되어 $0$이되는 것을 확인할 수 있습니다. 두번째 시나리오의 경우 겹치는 영역도 없지만 딱붙어서 $C$와 $A$와$B$의 합집합이 같은 경우입니다. 위와 같이 계산해보면 이 경우는 $GIOU$가 $0$이 나오는 것을 확인할 수 있습니다. 세번째 시나리오는 멀리 떨어져있는 경우입니다. 이때 $A$와 $B$의 합집합 대비 $C$가 커지게되면 점점 $0$에 가까워지고, 이때 $lim |AUB|/|C| -> 0$으로가면 $GIOU$는 결국 $C/C$ Term만 남음으로, $Regularization Term$은 $1$이되어 $GIOU = 0 - 1$로 -1이 될 것입니다. 이는 두개의 Bounding Box의 거리가 멀때 $IOU$와 다르게 얼마나 거리가 먼 지를 평가할 수 있음을 보입니다. 이러한 내용을 Property로 정리해보면 아래와 같습니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure10.png?raw=true" alt="Figure10">

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure11.png?raw=true" alt="Figure11">

위 알고리듬 표2는 위에서 다룬 알고리듬1의 좀 더 자세한 표현입니다. 알고리듬2의 내용은 위에서 정리한 내용과 같습니다. 좀 더 자세한 내용을 보고싶으시면 이 알고리듬 2를 참조하시면 됩니다. 이때 $L_GIOU = 1 - GIOU$로 되어있는데, 이는 GIOU가 -1 부터 1의 범위를 갖기 때문에 이를 Loss로써 활용하기 Positive 영역으로 Shift하기 위함입니다. 이를 통해 GIOU는 0부터 2의 양수 범위를 갖게 됩니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure12.png?raw=true" alt="Figure12">

위 그림은 이러한 내용은 시각화한 그림입니다. $L_n Norm$과 IOU, GIOU를 비교한 그림으로, $L_n Norm$은 상자의 크기나 위치 등에 영향을 안 받고 다 다른 케이스를 같은 값으로 표현한 반면에 IOU는 이를 반영하여 표현하고있습니다. GIOU의 경우 위의 케이스에서도 봤듯이 IOU와 같은 경향성을 갖지만, 좀 더 타이트한 값을 갖고있습니다. 이러한 IOU와 GIOU의 경향성은 아래의 그래프에도 확인할 수 있습니다. 본 연구에서는 제안한 GIOU를 바탕으로 Faster R-CNN, Mask R-CNN, Yolo 등을 학습시켜 성능향상을 보았는데요, 얼마나 향상되었는지는 다음 챕터에서 다룰 DIOU와 CIOU를 다루고 이들과 함께 보도록 하겠습니다.

<img src="https://github.com/EzoBear/EzoBear.github.io/blob/master/assets/images/post_images/2020-11-12-IOU/Figure13.png?raw=true" alt="Figure13">
